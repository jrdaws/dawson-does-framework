# Task: Implement Chunked Code Generation

**Priority:** P2 (Medium)
**Assigned To:** Platform Agent
**Created:** 2025-12-23 06:00
**Quality Score:** 8.2/10

---

## Context

PROJECT_STATUS.md identifies a known issue: **Code generation truncation** for complex projects at 12,000 tokens. Current workaround is to use 'quality' tier, but a proper fix requires chunked generation.

The Testing Agent verified live API works with maxTokens of 32,000, but complex multi-file outputs still risk truncation.

## Vision Alignment

- **Export-First**: Generated code must be complete and functional
- **Fail Gracefully**: Detect truncation and handle appropriately
- **Transparency**: Log when chunking occurs

## Task Objectives

### 1. Analyze Current Truncation Point

File: `packages/ai-agent/src/code-generator.ts`

- Current maxTokens: 32,000
- Truncation typically occurs at ~12,000 output tokens
- Complex projects may need 50,000+ tokens for full output

### 2. Implement Chunked Generation Strategy

**Approach A: Split by File Groups**

Generate code in chunks of 3-5 files at a time:

```typescript
async function generateCodeChunked(
  architecture: Architecture,
  input: ProjectInput,
  options: GenerateOptions
): Promise<CodeOutput> {
  const allFiles: CodeFile[] = [];
  const pages = architecture.pages;
  
  // Chunk pages into groups of 3
  const pageChunks = chunkArray(pages, 3);
  
  for (const chunk of pageChunks) {
    const chunkResult = await generateChunkCode(chunk, architecture, input, options);
    allFiles.push(...chunkResult.files);
    
    // Emit progress for streaming
    if (options.onStream) {
      options.onStream(`Generated ${allFiles.length} files...`, '');
    }
  }
  
  return { files: allFiles, integrationCode: [] };
}
```

**Approach B: Detect and Retry**

If response appears truncated, retry with smaller scope:

```typescript
function isResponseTruncated(response: string): boolean {
  // Check for incomplete JSON
  try {
    JSON.parse(response);
    return false;
  } catch {
    // Check if it looks like truncated JSON (ends mid-string, missing brackets)
    const lastChars = response.slice(-100);
    return !lastChars.includes('}') || response.split('{').length > response.split('}').length;
  }
}
```

### 3. Update Token Tracking

Track tokens per chunk and total:

```typescript
interface ChunkedGenerationMetrics {
  totalChunks: number;
  filesPerChunk: number[];
  tokensPerChunk: number[];
  totalTokens: number;
  truncationsDetected: number;
}
```

### 4. Maintain Streaming Compatibility

Chunked generation must still support streaming events:
- `chunk_start` - Starting chunk N of M
- `file_generated` - Each file as it completes
- `chunk_complete` - Chunk finished

### 5. Add Detection Metrics

Log when chunking is needed:

```typescript
if (estimatedTokens > CHUNK_THRESHOLD) {
  logger.info(`Large project detected: ~${estimatedTokens} tokens, using chunked generation`);
}
```

## Implementation Notes

- Start with a conservative chunk size (3 files)
- Each chunk prompt should include context about already-generated files
- Maintain consistent naming across chunks (avoid duplicate file names)
- Add `--no-chunk` flag for debugging

## Success Criteria

- [ ] Projects with 10+ files generate completely
- [ ] No truncated JSON responses
- [ ] Streaming still works with chunk progress
- [ ] Token tracking accurate across chunks
- [ ] All 668 tests pass
- [ ] Performance impact < 20% for small projects

## Test Cases

After implementation, test with:
```bash
# Complex project that previously truncated
node packages/ai-agent/test-runner.mjs "A SaaS platform with user authentication, team management, billing with Stripe, analytics dashboard, admin panel, and notification system"
```

## Reference

- `packages/ai-agent/src/code-generator.ts` - Current implementation
- `packages/ai-agent/src/index.ts` - Generation pipeline
- Testing Agent's completion report for current limits

## Handoff

When complete:
1. Move this file to `output/platform-agent/done/`
2. Create completion report with performance comparison
3. Update AI_GENERATION_ENGINE.md with chunking documentation
4. Commit: `feat(ai-agent): implement chunked code generation for large projects`

---

*Read and execute this task. Follow governance in AGENT_CONTEXT.md.*


