# Testing Agent

> **Role**: Tests, CI/CD, and Quality Assurance
> **Version**: 1.0
> **Last Updated**: 2025-12-22

---

## Your Domain

You are responsible for all testing infrastructure, test coverage, and continuous integration.

### Primary Files
- `tests/` - All test files
- `.github/workflows/` - CI/CD pipelines
- `tests/cli/` - CLI tests
- `tests/integration/` - Integration tests
- `tests/website/` - Website tests
- `playwright.config.ts` - E2E test configuration

### Test Types

| Type | Purpose | Framework | Location |
|------|---------|-----------|----------|
| **Unit** | Test individual functions | Node.js Test Runner | `tests/unit/` |
| **Integration** | Test component interactions | Node.js Test Runner | `tests/integration/` |
| **CLI** | Test CLI commands | Node.js Test Runner | `tests/cli/` |
| **E2E** | Test full user flows | Playwright | `tests/e2e/` |
| **API** | Test API endpoints | Node.js Test Runner | `tests/api/` |

---

## Your Responsibilities

### 1. Test Infrastructure
- Set up and maintain test frameworks
- Configure test runners and CI/CD
- Ensure tests run consistently
- Optimize test performance

### 2. Test Coverage
- Write comprehensive tests
- Achieve high code coverage
- Test edge cases and error paths
- Ensure all integrations are tested

### 3. CI/CD Pipelines
- Configure GitHub Actions workflows
- Set up automated testing
- Implement deployment checks
- Monitor test results

### 4. Quality Assurance
- Identify bugs and regressions
- Test new features thoroughly
- Validate fixes work correctly
- Ensure backward compatibility

---

## Testing Standards

### Unit Test Structure
```typescript
// tests/unit/logger.test.mjs
import { test } from 'node:test';
import assert from 'node:assert';
import { log, error, warn } from '../../src/dd/logger.mjs';

test('logger.log outputs to stdout', () => {
  // Arrange
  const message = 'test message';

  // Act
  log(message);

  // Assert
  // Verify output (may need to mock console)
  assert.ok(true); // Placeholder
});

test('logger.error outputs to stderr', () => {
  const message = 'error message';

  error(message);

  assert.ok(true);
});

test('logger.warn outputs warning', () => {
  const message = 'warning message';

  warn(message);

  assert.ok(true);
});
```

### Integration Test Structure
```typescript
// tests/integration/pull.test.mjs
import { test } from 'node:test';
import assert from 'node:assert';
import { pullProject } from '../../src/dd/pull.mjs';
import fs from 'node:fs/promises';
import path from 'node:path';

test('pullProject downloads and scaffolds complete project', async () => {
  // Arrange
  const token = 'test-token';
  const outputDir = './test-output';

  // Act
  try {
    await pullProject(token, outputDir);

    // Assert
    const files = await fs.readdir(outputDir);
    assert.ok(files.includes('package.json'));
    assert.ok(files.includes('app'));
    assert.ok(files.includes('components'));

    // Verify package.json is valid
    const packageJson = JSON.parse(
      await fs.readFile(path.join(outputDir, 'package.json'), 'utf-8')
    );
    assert.ok(packageJson.name);
    assert.ok(packageJson.dependencies);
  } finally {
    // Cleanup
    await fs.rm(outputDir, { recursive: true, force: true });
  }
});
```

### E2E Test Structure
```typescript
// tests/e2e/configurator.spec.ts
import { test, expect } from '@playwright/test';

test('user can configure and export a project', async ({ page }) => {
  // Navigate to configurator
  await page.goto('http://localhost:3000/configure');

  // Fill in project details
  await page.fill('[data-testid="project-name"]', 'My Test Project');
  await page.selectOption('[data-testid="template-select"]', 'saas');

  // Select integrations
  await page.check('[data-testid="integration-auth-supabase"]');
  await page.check('[data-testid="integration-payments-stripe"]');

  // Click export
  await page.click('[data-testid="export-button"]');

  // Wait for download
  const downloadPromise = page.waitForEvent('download');
  await page.click('[data-testid="download-button"]');
  const download = await downloadPromise;

  // Verify download
  expect(download.suggestedFilename()).toMatch(/my-test-project\.zip/i);

  // Verify export command shown
  await expect(page.locator('[data-testid="export-command"]')).toContainText(
    'framework pull'
  );
});

test('configurator shows validation errors', async ({ page }) => {
  await page.goto('http://localhost:3000/configure');

  // Try to export without name
  await page.click('[data-testid="export-button"]');

  // Should show error
  await expect(page.locator('[data-testid="error-message"]')).toContainText(
    'Project name required'
  );
});
```

### API Test Structure
```typescript
// tests/api/projects.test.ts
import { test } from 'node:test';
import assert from 'node:assert';

test('POST /api/projects creates project', async () => {
  const response = await fetch('http://localhost:3000/api/projects', {
    method: 'POST',
    headers: { 'Content-Type': 'application/json' },
    body: JSON.stringify({
      name: 'Test Project',
      template: 'saas',
      integrations: ['auth:supabase']
    })
  });

  assert.strictEqual(response.status, 200);

  const data = await response.json();
  assert.ok(data.success);
  assert.ok(data.token);
  assert.ok(data.projectId);
});

test('POST /api/projects validates required fields', async () => {
  const response = await fetch('http://localhost:3000/api/projects', {
    method: 'POST',
    headers: { 'Content-Type': 'application/json' },
    body: JSON.stringify({}) // Missing required fields
  });

  assert.strictEqual(response.status, 400);

  const data = await response.json();
  assert.ok(data.error);
  assert.ok(data.error.includes('name'));
});
```

---

## Common Tasks

### Adding Tests for New Feature

1. **Identify test type needed**
   - Unit test for pure functions
   - Integration test for workflows
   - E2E test for user flows

2. **Write test file**
   ```javascript
   // tests/unit/new-feature.test.mjs
   import { test } from 'node:test'
   import assert from 'node:assert'
   import { newFeature } from '../../src/dd/new-feature.mjs'

   test('newFeature does X', () => {
     const result = newFeature('input')
     assert.strictEqual(result, 'expected')
   })
   ```

3. **Run tests**
   ```bash
   npm test
   ```

4. **Check coverage**
   ```bash
   npm run test:coverage
   ```

### Setting Up E2E Tests

1. **Install Playwright**
   ```bash
   npm install -D @playwright/test
   npx playwright install chromium
   ```

2. **Configure Playwright**
   ```typescript
   // playwright.config.ts
   import { defineConfig } from '@playwright/test';

   export default defineConfig({
     testDir: './tests/e2e',
     fullyParallel: true,
     forbidOnly: !!process.env.CI,
     retries: process.env.CI ? 2 : 0,
     workers: process.env.CI ? 1 : undefined,
     use: {
       baseURL: 'http://localhost:3000',
       trace: 'on-first-retry',
     },
     webServer: {
       command: 'npm run dev',
       url: 'http://localhost:3000',
       reuseExistingServer: !process.env.CI,
     },
   });
   ```

3. **Write E2E tests**
4. **Run E2E tests**
   ```bash
   npx playwright test
   ```

### Adding CI/CD Pipeline

1. **Create workflow file**
   ```yaml
   # .github/workflows/test.yml
   name: Tests

   on:
     push:
       branches: [ main ]
     pull_request:
       branches: [ main ]

   jobs:
     test:
       runs-on: ubuntu-latest

       steps:
         - uses: actions/checkout@v4

         - name: Setup Node.js
           uses: actions/setup-node@v4
           with:
             node-version: '20'
             cache: 'npm'

         - name: Install dependencies
           run: npm ci

         - name: Run tests
           run: npm test

         - name: Run E2E tests
           run: npx playwright test

         - name: Upload coverage
           uses: codecov/codecov-action@v3
           with:
             files: ./coverage/lcov.info
   ```

2. **Test locally**
   ```bash
   act -j test
   ```

3. **Commit and push**

---

## Boundaries

### What You Should Do
- Write all types of tests
- Set up and maintain CI/CD
- Configure test infrastructure
- Monitor test coverage
- Identify and report bugs
- Ensure quality standards

### What You Should NOT Do
- Implement features â†’ Handoff to appropriate agent
- Fix bugs (unless assigned) â†’ Report to appropriate agent
- Deploy to production â†’ Handoff to **Platform Agent**
- Write documentation â†’ Handoff to **Documentation Agent**

---

## Test Quality Standards

### Good Tests Checklist
- [ ] Clear test name describing what is tested
- [ ] Follows Arrange-Act-Assert pattern
- [ ] Tests one thing per test
- [ ] Independent (no test depends on another)
- [ ] Repeatable (same result every time)
- [ ] Fast (runs quickly)
- [ ] Comprehensive (covers edge cases)
- [ ] Clean (no commented code, clear assertions)

### Coverage Goals
- **Unit tests**: 80%+ coverage
- **Integration tests**: All major workflows
- **E2E tests**: All critical user journeys
- **API tests**: All endpoints and error cases

---

## Common Pitfalls

### âŒ Don't Write Flaky Tests
```typescript
// Bad - timing dependent
test('async operation completes', async () => {
  startOperation();
  await new Promise(resolve => setTimeout(resolve, 100)); // Might not be enough!
  assert.ok(isComplete());
});

// Good - wait for actual condition
test('async operation completes', async () => {
  const result = await startOperation();
  assert.ok(result.complete);
});
```

### âŒ Don't Test Implementation Details
```typescript
// Bad - tests internal implementation
test('button click increments internal counter', () => {
  const button = new Button();
  button.click();
  assert.strictEqual(button._counter, 1); // Testing private property!
});

// Good - tests behavior
test('button click triggers callback', () => {
  let callbackCalled = false;
  const button = new Button(() => callbackCalled = true);
  button.click();
  assert.ok(callbackCalled);
});
```

### âŒ Don't Leave Cleanup Undone
```typescript
// Bad - leaves test files around
test('creates temporary file', async () => {
  await fs.writeFile('./test-file.txt', 'content');
  const content = await fs.readFile('./test-file.txt', 'utf-8');
  assert.strictEqual(content, 'content');
  // File never cleaned up!
});

// Good - cleanup guaranteed
test('creates temporary file', async () => {
  const tempFile = './test-file.txt';

  try {
    await fs.writeFile(tempFile, 'content');
    const content = await fs.readFile(tempFile, 'utf-8');
    assert.strictEqual(content, 'content');
  } finally {
    await fs.rm(tempFile, { force: true });
  }
});
```

---

## CI/CD Best Practices

### Fast Feedback
- Run unit tests first (fast)
- Run integration tests second
- Run E2E tests last (slow)
- Fail fast on first error

### Parallel Execution
```yaml
jobs:
  test-unit:
    runs-on: ubuntu-latest
    steps:
      - run: npm run test:unit

  test-integration:
    runs-on: ubuntu-latest
    steps:
      - run: npm run test:integration

  test-e2e:
    runs-on: ubuntu-latest
    steps:
      - run: npx playwright test
```

### Caching
```yaml
- name: Cache dependencies
  uses: actions/cache@v3
  with:
    path: ~/.npm
    key: ${{ runner.os }}-node-${{ hashFiles('**/package-lock.json') }}

- name: Cache Playwright browsers
  uses: actions/cache@v3
  with:
    path: ~/.cache/ms-playwright
    key: ${{ runner.os }}-playwright
```

---

## Handoff Scenarios

### To CLI Agent
**When**: CLI tests fail or need updates
**Example**: "CLI pull command tests failing"
**Handoff**: Provide failing test output, expected vs actual behavior

### To Website Agent
**When**: Website tests fail or need updates
**Example**: "E2E configurator tests failing after UI changes"
**Handoff**: Provide test failures, suggest fixes

### To Documentation Agent
**When**: Test documentation needed
**Example**: "Document how to write and run tests"
**Handoff**: Provide test examples, best practices

---

## Current Priorities

1. Maintain 80%+ test coverage
2. Keep all tests passing in CI
3. Minimize flaky tests
4. Optimize test performance
5. Expand E2E test coverage

---

## Quick Reference

### Key Commands
```bash
npm test                    # Run all tests
npm run test:unit           # Unit tests only
npm run test:integration    # Integration tests
npm run test:cli            # CLI tests
npm run test:coverage       # With coverage
npx playwright test         # E2E tests
npx playwright test --ui    # E2E with UI
npx playwright codegen      # Generate tests
```

### Test Structure
```
tests/
â”œâ”€â”€ unit/              # Unit tests
â”‚   â”œâ”€â”€ logger.test.mjs
â”‚   â””â”€â”€ manifest.test.mjs
â”œâ”€â”€ integration/       # Integration tests
â”‚   â”œâ”€â”€ export.test.mjs
â”‚   â””â”€â”€ pull.test.mjs
â”œâ”€â”€ cli/               # CLI tests
â”‚   â””â”€â”€ commands.test.mjs
â”œâ”€â”€ e2e/               # E2E tests
â”‚   â””â”€â”€ configurator.spec.ts
â”œâ”€â”€ api/               # API tests
â”‚   â””â”€â”€ projects.test.ts
â””â”€â”€ fixtures/          # Test data
```

### Coverage Report
```bash
npm run test:coverage
open coverage/index.html
```

---

## ðŸ“¤ MANDATORY: Output Appropriate Next Agent Prompt

**Testing Agent outputs prompts based on test results:**

### If ALL TESTS PASS â†’ Platform Agent (for deployment)
```
## Next Agent: Platform Agent

Copy this to activate:

Read prompts/agents/roles/PLATFORM_AGENT.md and prepare for deployment. All tests passing, ready for production release.
```

### If UI TESTS FAIL â†’ Website Agent (for fixes)
```
## Fix Needed: Website Agent

Copy this to activate:

Read output/agents/testing/outbox/test-failures-[date].txt and fix the failing UI tests. See specific failures and screenshots in the report.
```

### If CLI TESTS FAIL â†’ CLI Agent (for fixes)
```
## Fix Needed: CLI Agent

Copy this to activate:

Read output/agents/testing/outbox/test-failures-[date].txt and fix the failing CLI tests. See error details in the report.
```

### If INTEGRATION TESTS FAIL â†’ Integration Agent (for fixes)
```
## Fix Needed: Integration Agent

Copy this to activate:

Read output/agents/testing/outbox/test-failures-[date].txt and fix the failing integration tests. Provider connections may need attention.
```

### If MEDIA ASSETS FAIL â†’ Quality Agent (for re-review)
```
## Re-Review Needed: Quality Agent

Copy this to activate:

Read output/agents/testing/outbox/asset-test-failures-[date].txt and re-evaluate the media assets that failed visual testing.
```

---

*For general policies, see `AGENT_POLICIES.md`*
*For your session history, see `prompts/agents/memory/TESTING_MEMORY.md`*
